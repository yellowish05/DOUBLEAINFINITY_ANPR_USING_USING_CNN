{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing needed libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "import io\n",
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Start of:\n",
    "Setting up full paths\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full or absolute path to 'Section4' with preprocessed datasets\n",
    "# (!) On Windows, the path should look like following:\n",
    "# r'C:\\Users\\your_name\\PycharmProjects\\CNNCourse\\Section4'\n",
    "# or:\n",
    "# 'C:\\\\Users\\\\your_name\\\\PycharmProjects\\\\CNNCourse\\\\Section4'\n",
    "\n",
    "full_path_to_Section4 = \\\n",
    "    'C:/Users/yelti/THESIS-FINAL/CNN/Section4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full or absolute path to 'Section5' with designed models\n",
    "# (!) On Windows, the path should look like following:\n",
    "# r'C:\\Users\\your_name\\PycharmProjects\\CNNCourse\\Section5'\n",
    "# or:\n",
    "# 'C:\\\\Users\\\\your_name\\\\PycharmProjects\\\\CNNCourse\\\\Section5'\n",
    "\n",
    "full_path_to_Section5 = \\\n",
    "    'C:/Users/yelti/THESIS-FINAL/CNN/Section4/Section5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Start of:\n",
    "Loading saved model\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "# (!) On Windows, it might need to change\n",
    "# this: + '/' +\n",
    "# to this: + '\\' +\n",
    "# or to this: + '\\\\' +\n",
    "\n",
    "model = load_model(full_path_to_Section5 + '/' +\n",
    "                   'custom' + '/' +\n",
    "                   'License_Model.h5')\n",
    "                   # Check point\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Start of:\n",
    "Loading and assigning best weights\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and assigning best weights\n",
    "# (!) On Windows, it might need to change\n",
    "# this: + '/' +\n",
    "# to this: + '\\' +\n",
    "# or to this: + '\\\\' +\n",
    "\n",
    "model.load_weights(full_path_to_Section5 + '/' + 'custom' + '/' + 'License_Model.h5')\n",
    "\n",
    "# Check point\n",
    "print('Best weights are loaded and assigned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Start of:\n",
    "Preparing labels\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining list with labels for custom dataset\n",
    "labels = ['LicensePlateN','LicensePlateO']\n",
    "\n",
    "# Check point\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Start of:\n",
    "Loading saved Mean Image and Standard Deviation\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening saved Mean Image for GRAY custom dataset\n",
    "# Initiating File object\n",
    "# Opening file in reading mode by 'r'\n",
    "# (!) On Windows, it might need to change\n",
    "# this: + '/' +\n",
    "# to this: + '\\' +\n",
    "# or to this: + '\\\\' +\n",
    "with h5py.File(full_path_to_Section5 + '/' +\n",
    "                'custom' + '/' +\n",
    "                'mean_rgb_dataset_custom.hdf5', 'r') as f:\n",
    "    # Extracting saved array for Mean Image\n",
    "    # Saving it into new variable\n",
    "    mean_gray = f['mean']  # HDF5 dataset\n",
    "    # Converting it into Numpy array\n",
    "    mean_gray = np.array(mean_gray)  # Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening saved Standard Deviation for GRAY custom dataset\n",
    "# Initiating File object\n",
    "# Opening file in reading mode by 'r'\n",
    "# (!) On Windows, it might need to change\n",
    "# this: + '/' +\n",
    "# to this: + '\\' +\n",
    "# or to this: + '\\\\' +\n",
    "with h5py.File(full_path_to_Section4 + '/' +\n",
    "               'custom' + '/' +\n",
    "               'std_rgb_dataset_custom.hdf5', 'r') as f:\n",
    "    # Extracting saved array for Standard Deviation\n",
    "    # Saving it into new variable\n",
    "    std_gray = f['std']  # HDF5 dataset\n",
    "    # Converting it into Numpy array\n",
    "    std_gray = np.array(std_gray)  # Numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Start of:\n",
    "Preparing function to plot bar chart\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to plot bar chart with scores values\n",
    "def bar_chart(obtained_scores, classes_names):\n",
    "     # Arranging X axis\n",
    "     x_positions = np.arange(obtained_scores.size)\n",
    "\n",
    "     # Creating bar chart\n",
    "     bars = plt.bar(x_positions, obtained_scores, align='center', alpha=0.6)\n",
    "\n",
    "     # Highlighting the highest bar\n",
    "     bars[np.argmax(obtained_scores)].set_color('red')\n",
    "\n",
    "     # Giving labels to bars along X axis\n",
    "     plt.xticks(x_positions, classes_names, rotation=10, fontsize=15)\n",
    "\n",
    "     # Giving names to axes\n",
    "     plt.xlabel('Class', fontsize=20)\n",
    "     plt.ylabel('Value', fontsize=20)\n",
    "\n",
    "     # Giving name to bar chart\n",
    "     plt.title('Obtained Scores', fontsize=20)\n",
    "\n",
    "     # Adjusting borders of the plot\n",
    "     plt.tight_layout(pad=2.5)\n",
    "\n",
    "     # Initializing object of the buffer\n",
    "     b = io.BytesIO()\n",
    "\n",
    "     # Saving bar chart into the buffer\n",
    "     plt.savefig(b, format='png', dpi=200)\n",
    "\n",
    "     # Closing plot with bar chart\n",
    "     plt.close()\n",
    "\n",
    "     # Moving pointer to the beginning of the buffer\n",
    "     b.seek(0)\n",
    "\n",
    "     # Reading bar chart from the buffer\n",
    "     bar_image = np.frombuffer(b.getvalue(), dtype=np.uint8)\n",
    "\n",
    "     # Closing buffer\n",
    "     b.close()\n",
    "\n",
    "     # Decoding buffer\n",
    "     bar_image = cv2.imdecode(bar_image, 1)\n",
    "\n",
    "     # Returning Numpy array with bar chart\n",
    "     return bar_image\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('Function to plot Bar Chart is successfully defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Start of:\n",
    "Preparing OpenCV windows to be shown\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving names to the windows\n",
    "# Specifying that windows are resizable\n",
    "\n",
    "# Window to show current view from camera in Real Time\n",
    "cv2.namedWindow('Current view', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Window to show cut fragment\n",
    "cv2.namedWindow('Cut fragment', cv2.WINDOW_NORMAL)\n",
    "\n",
    "#  # Window to show classification result\n",
    "# cv2.namedWindow('Classified as', cv2.WINDOW_NORMAL)\n",
    "\n",
    "#  # Window to show bar chart with scores\n",
    "# cv2.namedWindow('Scores', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Check point\n",
    "print('OpenCV windows are ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Start of:\n",
    "Reading frames from camera in the loop\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining 'VideoCapture' object\n",
    "# to read stream video from camera\n",
    "# Index of the built-in camera is usually 0\n",
    "# Try to select other cameras by passing 1, 2, 3, etc.\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# Defining counter for FPS (Frames Per Second)\n",
    "counter = 0\n",
    "\n",
    "# Starting timer for FPS\n",
    "# Getting current time point in seconds\n",
    "fps_start = timer()\n",
    "\n",
    "\n",
    "# Creating image with black background\n",
    "temp = np.zeros((720, 1280, 3), np.uint8)\n",
    "\n",
    "\n",
    "# Defining loop to catch frames\n",
    "while True:\n",
    "    # Capturing frames one-by-one from camera\n",
    "    _, frame_bgr = camera.read()\n",
    "\n",
    "    \"\"\"\n",
    "    Start of:\n",
    "    Detecting object\n",
    "    \"\"\"\n",
    "\n",
    "    # Converting caught frame to HSV colour space\n",
    "    frame_hsv = cv2.cvtColor(frame_bgr, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Applying mask with founded boundary numbers\n",
    "    # gray = cv2.cvtColor(frame_hsv, cv2.IMREAD_GRAYSCALE)\n",
    "    # bfilter = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "    edged = cv2.Canny(frame_hsv, 30, 200)\n",
    "    #mask = np.zeros(frame_hsv, np.uint8)\n",
    "\n",
    "    # Finding contours\n",
    "    # All found contours are placed into a list\n",
    "    # Every individual contour is a Numpy array of (x, y) coordinates,\n",
    "    # that represent boundary points of detected object\n",
    "    contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # contours, _ = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    # Sorting contours from biggest to smallest\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    \"\"\"\n",
    "    End of:\n",
    "    Detecting object\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Start of:\n",
    "    Classifying detected object\n",
    "    \"\"\"\n",
    "\n",
    "    # If any contour is found, extracting coordinates of the biggest one\n",
    "    if contours:\n",
    "        # Getting rectangle coordinates and spatial size of the biggest contour\n",
    "        # Function 'cv2.boundingRect()' returns an approximate rectangle,\n",
    "        # that covers the region around found contour\n",
    "        (x_min, y_min, box_width, box_height) = cv2.boundingRect(contours[0])\n",
    "\n",
    "        # Drawing obtained rectangle on the current BGR frame\n",
    "        cv2.rectangle(frame_bgr, (x_min, y_min),\n",
    "                      (x_min + box_width, y_min + box_height),\n",
    "                      (230, 161, 0), 3)\n",
    "\n",
    "        # # Putting text above rectangle\n",
    "        # cv2.putText(frame_bgr, 'DETECTED', (x_min - 5, y_min - 25),\n",
    "        #             cv2.FONT_HERSHEY_SIMPLEX, 1.0, (230, 161, 0), 2)\n",
    "\n",
    "        \"\"\"\n",
    "        Start of:\n",
    "        Cutting detected fragment\n",
    "        \"\"\"\n",
    "\n",
    "        # Cutting detected fragment from BGR frame\n",
    "        cut_fragment_bgr = frame_bgr[y_min + int(box_height * 0.1):\n",
    "                                     y_min + box_height - int(box_height * 0.1),\n",
    "                                     x_min + int(box_width * 0.1):\n",
    "                                     x_min + box_width - int(box_width * 0.1)]\n",
    "\n",
    "        \"\"\"\n",
    "        End of:\n",
    "        Cutting detected fragment\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        Start of:\n",
    "        Preprocessing cut fragment\n",
    "        \"\"\"\n",
    "\n",
    "        # Converting frame to GRAY by OpenCV function\n",
    "        frame_gray = cv2.cvtColor(cut_fragment_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Resizing frame to 64 by 64 pixels size\n",
    "        frame_gray = cv2.resize(frame_gray,\n",
    "                                (100, 100),\n",
    "                                interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # # Extending dimension from (height, width) to (height, width, 1)\n",
    "        frame_gray = frame_gray[:, :, np.newaxis]\n",
    "\n",
    "        # # Implementing normalization by dividing image's pixels on 255.0\n",
    "        frame_gray_255 = frame_gray / 255.0\n",
    "\n",
    "        # # Implementing normalization by subtracting Mean Image\n",
    "        frame_gray_255_mean = frame_gray_255 - mean_gray\n",
    "\n",
    "        # # Implementing preprocessing by dividing on Standard Deviation\n",
    "        frame_gray_255_mean_std = frame_gray_255_mean / std_gray\n",
    "\n",
    "        # # Extending dimension from (height, width, 1)\n",
    "        # # to (1, height, width, 1)\n",
    "        frame_gray_255_mean_std = frame_gray_255_mean_std[np.newaxis, :, :, :]\n",
    "\n",
    "        \n",
    "        # reader = easyocr.Reader(['en'])\n",
    "        # result = reader.readtext(frame_gray)\n",
    "        # text = result[0][-2]\n",
    "        # # print(text)\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        End of:\n",
    "        Preprocessing cut fragment\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        Start of:\n",
    "        Implementing forward pass\n",
    "        \"\"\"\n",
    "\n",
    "        # # Testing RGB custom model trained on dataset:\n",
    "        # # dataset_custom_gray_255_mean_std.hdf5\n",
    "        # # Caught frame is preprocessed in the same way\n",
    "        # # Measuring classification time\n",
    "        start = timer()\n",
    "        scores = model.predict(frame_gray_255_mean_std)\n",
    "        end = timer()\n",
    "\n",
    "        # # Scores are given as 5 numbers of predictions for each class\n",
    "        # # Getting index of only one class with maximum value\n",
    "        prediction = np.argmax(scores)\n",
    "\n",
    "        \"\"\"\n",
    "        End of:\n",
    "        Implementing forward pass\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        Start of:\n",
    "        Showing OpenCV windows\n",
    "        \"\"\"\n",
    "\n",
    "        # Showing current view from camera in Real Time\n",
    "        # Pay attention! 'cv2.imshow' takes images in BGR format\n",
    "        cv2.imshow('Current view', frame_bgr)\n",
    "\n",
    "        # Showing cut fragment\n",
    "        cv2.imshow('Cut fragment', cut_fragment_bgr)\n",
    "\n",
    "        # Changing background to BGR(230, 161, 0)\n",
    "        # B = 230, G = 161, R = 0\n",
    "        temp[:, :, 0] = 230\n",
    "        temp[:, :, 1] = 161\n",
    "        temp[:, :, 2] = 0\n",
    "\n",
    "        # # Adding text with current label\n",
    "        cv2.putText(temp, labels[int(prediction)], (100, 200),\n",
    "                     cv2.FONT_HERSHEY_TRIPLEX, 6, (255, 255, 255), 6, cv2.LINE_AA)\n",
    "\n",
    "        # # Adding text with obtained confidence score to image with label\n",
    "        cv2.putText(temp, 'Score : ' + '{0:.5f}'.format(scores[0][prediction]),\n",
    "                     (100, 450), cv2.FONT_HERSHEY_DUPLEX, 4, (255, 255, 255),\n",
    "                     4, cv2.LINE_AA)\n",
    "\n",
    "        # # Adding text with time spent for classification to image with label\n",
    "        cv2.putText(temp, 'Time  : ' + '{0:.5f}'.format(end - start),\n",
    "                     (100, 600), cv2.FONT_HERSHEY_DUPLEX, 4, (255, 255, 255),\n",
    "                     4, cv2.LINE_AA)\n",
    "\n",
    "        # # Showing image with respect to classification results\n",
    "        cv2.imshow('Classified as', temp)\n",
    "\n",
    "        # # Showing bar chart\n",
    "        cv2.imshow('Scores', bar_chart(scores[0], labels))\n",
    "\n",
    "        \"\"\"\n",
    "        End of:\n",
    "        Showing OpenCV windows\n",
    "        \"\"\"\n",
    "\n",
    "    # If no contour is found, showing OpenCV windows with information\n",
    "    else:\n",
    "        # Showing current view from camera in Real Time\n",
    "        # Pay attention! 'cv2.imshow' takes images in BGR format\n",
    "        cv2.imshow('Current view', frame_bgr)\n",
    "\n",
    "        # Changing background to BGR(230, 161, 0)\n",
    "        # B = 230, G = 161, R = 0\n",
    "        temp[:, :, 0] = 230\n",
    "        temp[:, :, 1] = 161\n",
    "        temp[:, :, 2] = 0\n",
    "\n",
    "        # Adding text with information\n",
    "        cv2.putText(temp, 'No object', (100, 450),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, 4, (255, 255, 255), 4, cv2.LINE_AA)\n",
    "\n",
    "        # Showing information in prepared OpenCV windows\n",
    "        cv2.imshow('Cut fragment', temp)\n",
    "        cv2.imshow('Classified as', temp)\n",
    "        cv2.imshow('Scores', temp)\n",
    "\n",
    "    \"\"\"\n",
    "    End of:\n",
    "    Classifying detected object\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Start of:\n",
    "    Calculating FPS\n",
    "    \"\"\"\n",
    "\n",
    "    # Increasing counter for FPS\n",
    "    counter += 1\n",
    "\n",
    "    # Stopping timer for FPS\n",
    "    # Getting current time point in seconds\n",
    "    fps_stop = timer()\n",
    "\n",
    "    # Checking if timer reached 1 second\n",
    "    # Comparing\n",
    "    if fps_stop - fps_start >= 1.0:\n",
    "        # # Showing FPS rate\n",
    "        # print('FPS rate is: ', counter)\n",
    "\n",
    "        # Reset FPS counter\n",
    "        counter = 0\n",
    "\n",
    "        # Restart timer for FPS\n",
    "        # Getting current time point in seconds\n",
    "        fps_start = timer()\n",
    "\n",
    "    \"\"\"\n",
    "    End of:\n",
    "    Calculating FPS\n",
    "    \"\"\"\n",
    "\n",
    "    # Breaking the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\"\"\"\n",
    "End of:\n",
    "Reading frames from camera in the loop\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Releasing camera\n",
    "camera.release()\n",
    "\n",
    "# Destroying all opened OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "376a020b01a543d19dd68d85ba0a5c92476c1b990158447245e1870a3a898a8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
